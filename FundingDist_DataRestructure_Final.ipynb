{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a feature class from the layer package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in source: 10278\n",
      "Feature class has been successfully exported to: C:\\Users\\gcowan\\Documents\\ArcGIS\\Projects\\Distribution Analysis\\Data Restructure\\Data_Restructure\\Data_Restructure.gdb\n"
     ]
    }
   ],
   "source": [
    "# Define file path to layer package and geodatabase; file suffix\n",
    "FundingDist_lpkx = r\"C:\\Users\\gcowan\\Documents\\ArcGIS\\Projects\\Distribution Analysis\\Data Restructure\\Data_Restructure\\FundingDistribution_CCIgdbAR24_prelim.lpkx\"\n",
    "project_gdb = r\"C:\\Users\\gcowan\\Documents\\ArcGIS\\Projects\\Distribution Analysis\\Data Restructure\\Data_Restructure\\Data_Restructure.gdb\"\n",
    "suffix = \"AR24\"\n",
    "\n",
    "# Define the target feature class path in the project geodatabase where you would like to export features to\n",
    "Funding_Dist = f\"{project_gdb}\\\\Funding_Dist_{suffix}\"\n",
    "\n",
    "# Make a feature layer from the layer package (.lpkx)\n",
    "arcpy.management.MakeFeatureLayer(FundingDist_lpkx, \"temp_layer\")\n",
    "\n",
    "# Clear any existing selection\n",
    "arcpy.management.SelectLayerByAttribute(\"temp_layer\", \"CLEAR_SELECTION\")\n",
    "\n",
    "# Ensure all features will be included\n",
    "count = int(arcpy.management.GetCount(\"temp_layer\")[0])\n",
    "print(f\"Number of features in source: {count}\")\n",
    "\n",
    "# Export the feature layer to your project geodatabase\n",
    "arcpy.management.CopyFeatures(\"temp_layer\", Funding_Dist)\n",
    "\n",
    "# Optional cleanup if needed (delete the temporary layer)\n",
    "arcpy.management.Delete(\"temp_layer\")\n",
    "\n",
    "print(f\"Feature class has been successfully exported to: {project_gdb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate fields for final layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field 'PctBIPOC' has been calculated with NULLs for invalid values.\n"
     ]
    }
   ],
   "source": [
    "# PctBIPOC\n",
    "\n",
    "BIPOC_fields = [\"Hispanic\", \"AfricanAm\", \"NativeAm\", \"OtherMult\", \"AAPI\"]\n",
    "new_field = \"PctBIPOC\"\n",
    "\n",
    "# Add the new field \n",
    "if new_field not in [f.name for f in arcpy.ListFields(Funding_Dist)]:\n",
    "    arcpy.AddField_management(Funding_Dist, new_field, \"DOUBLE\")\n",
    "\n",
    "# Use an UpdateCursor to calculate the sum of BIPOC percentages\n",
    "with arcpy.da.UpdateCursor(Funding_Dist, BIPOC_fields + [new_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        # Check for invalid values (None, -999, -1998) \n",
    "        if any(value in (None, -999, -1998) for value in row[:-1]):\n",
    "            row[-1] = None  # Assign NULL if invalid values are present\n",
    "        else:\n",
    "            # Sum the values and cap at 100 if no invalid values\n",
    "            total = sum(value for value in row[:-1])\n",
    "            row[-1] = min(total, 100)\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(f\"Field '{new_field}' has been calculated with NULLs for invalid values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field 'BIPOCMaj' has been populated with NULL for missing demographic information.\n"
     ]
    }
   ],
   "source": [
    "# BIPOCMaj\n",
    "\n",
    "classification_field = \"BIPOCMaj\"\n",
    "new_field = \"PctBIPOC\"\n",
    "\n",
    "# Add the new field\n",
    "if classification_field not in [f.name for f in arcpy.ListFields(Funding_Dist)]:\n",
    "    arcpy.AddField_management(Funding_Dist, classification_field, \"TEXT\", field_length=10)\n",
    "\n",
    "# Use an UpdateCursor to classify the rows\n",
    "with arcpy.da.UpdateCursor(Funding_Dist, [new_field, classification_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] == 0 or row[0] is None:  # Set to NULL if PctBIPOC is 0 or null\n",
    "            row[1] = None\n",
    "        else:\n",
    "            row[1] = \"BIPOC\" if row[0] > 0 else \"White\"\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(f\"Field '{classification_field}' has been populated with NULL for missing demographic information.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field 'DemogMaj' has been populated with NULL for missing demographic information.\n"
     ]
    }
   ],
   "source": [
    "# DemogMaj\n",
    "\n",
    "fields_to_compare = [\"Hispanic\", \"AfricanAm\", \"NativeAm\", \"OtherMult\", \"AAPI\", \"White\"]\n",
    "classification_field = \"DemogMaj\"\n",
    "\n",
    "# Add the classification field\n",
    "if classification_field not in [f.name for f in arcpy.ListFields(Funding_Dist)]:\n",
    "    arcpy.AddField_management(Funding_Dist, classification_field, \"TEXT\", field_length=50)\n",
    "\n",
    "# Use an UpdateCursor to classify based on the greatest value\n",
    "with arcpy.da.UpdateCursor(Funding_Dist, fields_to_compare + [classification_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        # Create a dictionary of field names and their values\n",
    "        field_values = {field: value for field, value in zip(fields_to_compare, row[:-1]) if value is not None}\n",
    "        if field_values:  # Ensure there are non-null values\n",
    "            # Find the field with the greatest value\n",
    "            majority_field = max(field_values, key=field_values.get)\n",
    "            row[-1] = majority_field  # Set the classification to the field name\n",
    "        else:\n",
    "            row[-1] = None  # Set to None if all values are null\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(f\"Field '{classification_field}' has been populated with NULL for missing demographic information.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field 'NOPPGGRF' has been calculated.\n"
     ]
    }
   ],
   "source": [
    "# NOPPGGRF\n",
    "NOPPGGRF_fields = [\"point_noppggrf_total\", \"Poly_NOPPGGRF_TOTAL\", \"CT_NOPPGGRF_TOTAL\", \"Line_NOPPGGRF_TOTAL\"]\n",
    "new_field = \"NOPPGGRF\"\n",
    "\n",
    "# Add the new field \n",
    "if new_field not in [f.name for f in arcpy.ListFields(Funding_Dist)]:\n",
    "    arcpy.AddField_management(Funding_Dist, new_field, \"DOUBLE\")\n",
    "\n",
    "# Use an UpdateCursor to calculate the sum of the fields\n",
    "with arcpy.da.UpdateCursor(Funding_Dist, NOPPGGRF_fields + [new_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        # Sum the values of the fields, treating None as 0\n",
    "        total = sum(value if value is not None else 0 for value in row[:-1])  # Ignore the last value (new_field)\n",
    "        row[-1] = total  # Set the sum in the new field\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(f\"Field '{new_field}' has been calculated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field 'PPGGRF' has been calculated.\n"
     ]
    }
   ],
   "source": [
    "# PPGGRF\n",
    "PPGGRF_fields = [\"point_ppggrf_total\", \"Poly_PPGGRF_TOTAL\", \"CT_PPGGRF_TOTAL\", \"Line_PPGGRF_TOTAL\"]\n",
    "new_field = \"PPGGRF\"\n",
    "\n",
    "# Add the new field \n",
    "if new_field not in [f.name for f in arcpy.ListFields(Funding_Dist)]:\n",
    "    arcpy.AddField_management(Funding_Dist, new_field, \"DOUBLE\")\n",
    "\n",
    "# Use an UpdateCursor to calculate the sum of the fields\n",
    "with arcpy.da.UpdateCursor(Funding_Dist, PPGGRF_fields + [new_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        # Sum the values of the fields, treating None as 0\n",
    "        total = sum(value if value is not None else 0 for value in row[:-1])  \n",
    "        row[-1] = total  # Set the sum in the new field\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(f\"Field '{new_field}' has been calculated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field 'GGRF' has been calculated.\n"
     ]
    }
   ],
   "source": [
    "# GGRF\n",
    "GGRF_fields = [\"point_ggrf_total\", \"Poly_GGRF_TOTAL\", \"CT_GGRF_TOTAL\", \"Line_GGRF_TOTAL\"]\n",
    "new_field = \"GGRF\"\n",
    "\n",
    "# Add the new field \n",
    "if new_field not in [f.name for f in arcpy.ListFields(Funding_Dist)]:\n",
    "    arcpy.AddField_management(Funding_Dist, new_field, \"DOUBLE\")\n",
    "\n",
    "# Use an UpdateCursor to calculate the sum of the fields\n",
    "with arcpy.da.UpdateCursor(Funding_Dist, GGRF_fields + [new_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        # Sum the values of the fields, treating None as 0\n",
    "        total = sum(value if value is not None else 0 for value in row[:-1])  \n",
    "        row[-1] = total  # Set the sum in the new field\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(f\"Field '{new_field}' has been calculated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCI Percentile values rounded to two decimal places have been calculated and stored in the field 'CCI_pct'.\n"
     ]
    }
   ],
   "source": [
    "# CCI_pct\n",
    "\n",
    "input_field = \"GGRF\"\n",
    "percentile_field = \"CCI_pct\"\n",
    "\n",
    "# Add the new percentile field \n",
    "if percentile_field not in [f.name for f in arcpy.ListFields(Funding_Dist)]:\n",
    "    arcpy.AddField_management(Funding_Dist, percentile_field, \"DOUBLE\")\n",
    "\n",
    "# Step 1: Extract values from the source field\n",
    "values = []\n",
    "with arcpy.da.SearchCursor(Funding_Dist, [input_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None:  # Exclude None values\n",
    "            values.append(row[0])\n",
    "\n",
    "# Step 2: Calculate percentiles as decimals\n",
    "values = sorted(values)  # Sort values for percentile calculation\n",
    "percentile_ranks = {value: i / (len(values) - 1) for i, value in enumerate(values)} \n",
    "\n",
    "# Step 3: Update the percentile field\n",
    "with arcpy.da.UpdateCursor(Funding_Dist, [input_field, percentile_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None:  # Check for valid values\n",
    "            # Assign the rounded decimal percentile rank to the new field\n",
    "            row[1] = round(percentile_ranks[row[0]], 2)\n",
    "        else:\n",
    "            row[1] = None  # Assign NULL for invalid values\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(f\"CCI Percentile values rounded to two decimal places have been calculated and stored in the field '{percentile_field}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCI deciles have been calculated and stored in the field 'CCIdecile'.\n"
     ]
    }
   ],
   "source": [
    "# CCIdecile\n",
    "\n",
    "input_field = \"GGRF\"\n",
    "category_field = \"CCIdecile\" \n",
    "\n",
    "# Add the new category field \n",
    "if category_field not in [f.name for f in arcpy.ListFields(Funding_Dist)]:\n",
    "    arcpy.AddField_management(Funding_Dist, category_field, \"TEXT\", field_length=50) \n",
    "\n",
    "# Step 1: Extract values from the source field\n",
    "values = []\n",
    "with arcpy.da.SearchCursor(Funding_Dist, [input_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None:  # Exclude None values\n",
    "            values.append(row[0])\n",
    "\n",
    "# Step 2: Sort values and define categories\n",
    "values = sorted(values)  # Sort values for decile calculation\n",
    "categories = [\n",
    "    \"Lowest Percentile\",\n",
    "    \">10th-20th Percentile\",\n",
    "    \">20th-30th Percentile\",\n",
    "    \">30th-40th Percentile\",\n",
    "    \">40th-50th Percentile\",\n",
    "    \">50th-60th Percentile\",\n",
    "    \">60th-70th Percentile\",\n",
    "    \">70th-80th Percentile\",\n",
    "    \">80th-90th Percentile\",\n",
    "    \"Highest Percentile\"\n",
    "]\n",
    "category_mapping = {value: categories[int(i / (len(values) / 10))] for i, value in enumerate(values)}\n",
    "\n",
    "# Step 3: Update the category field\n",
    "with arcpy.da.UpdateCursor(Funding_Dist, [input_field, category_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None:  # Check for valid values\n",
    "            # Assign the category label to the new field\n",
    "            row[1] = category_mapping[row[0]]\n",
    "        else:\n",
    "            row[1] = None  # Assign NULL for invalid values\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(f\"CCI deciles have been calculated and stored in the field '{category_field}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCI quartile categories have been calculated and stored in the field 'CCIquartile'.\n"
     ]
    }
   ],
   "source": [
    "# CCIquartile\n",
    "\n",
    "input_field = \"GGRF\"\n",
    "category_field = \"CCIquartile\" \n",
    "\n",
    "# Add the new category field \n",
    "if category_field not in [f.name for f in arcpy.ListFields(Funding_Dist)]:\n",
    "    arcpy.AddField_management(Funding_Dist, category_field, \"TEXT\", field_length=50) \n",
    "\n",
    "# Step 1: Extract values from the source field\n",
    "values = []\n",
    "with arcpy.da.SearchCursor(Funding_Dist, [input_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None:  # Exclude None values\n",
    "            values.append(row[0])\n",
    "\n",
    "# Step 2: Sort values and define categories\n",
    "values = sorted(values)  # Sort values for quartile calculation\n",
    "categories = [\n",
    "    \"Lowest Quartile\",       # 0% to 25%\n",
    "    \">25th-50th Quartile\",   # 25% to 50%\n",
    "    \">50th-75th Quartile\",   # 50% to 75%\n",
    "    \"Highest Quartile\"       # 75% to 100%\n",
    "]\n",
    "quartile_mapping = {value: categories[int(i / (len(values) / 4))] for i, value in enumerate(values)}\n",
    "\n",
    "# Step 3: Update the category field\n",
    "with arcpy.da.UpdateCursor(Funding_Dist, [input_field, category_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None:  # Check for valid values\n",
    "            # Assign the quartile label to the new field\n",
    "            row[1] = quartile_mapping[row[0]]\n",
    "        else:\n",
    "            row[1] = None  # Assign NULL for invalid values\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(f\"CCI quartile categories have been calculated and stored in the field '{category_field}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per capita funding values have been calculated and stored in the field 'CCIpc'.\n"
     ]
    }
   ],
   "source": [
    "# CCIpc\n",
    "\n",
    "input_field = \"GGRF\"\n",
    "population_field = \"Pop2020Rounded\"\n",
    "per_capita_field = \"CCIpc\"\n",
    "\n",
    "# Add the new per capita field \n",
    "if per_capita_field not in [f.name for f in arcpy.ListFields(Funding_Dist)]:\n",
    "    arcpy.AddField_management(Funding_Dist, per_capita_field, \"DOUBLE\") \n",
    "\n",
    "# Calculate per capita funding\n",
    "with arcpy.da.UpdateCursor(Funding_Dist, [input_field, population_field, per_capita_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        funding = row[0]\n",
    "        population = row[1]\n",
    "\n",
    "        # Check if population is valid and non-zero\n",
    "        if population and population > 0:\n",
    "            row[2] = funding / population  # Calculate per capita funding\n",
    "        else:\n",
    "            row[2] = None  # Assign NULL if population is 0 or None\n",
    "\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(f\"Per capita funding values have been calculated and stored in the field '{per_capita_field}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCIpc Percentile values rounded to two decimal places have been calculated and stored in the field 'CCIpcPct'.\n"
     ]
    }
   ],
   "source": [
    "# CCIpcPct\n",
    "\n",
    "input_field = \"CCIpc\"\n",
    "percentile_field = \"CCIpcPct\"\n",
    "\n",
    "# Add the new percentile field\n",
    "if percentile_field not in [f.name for f in arcpy.ListFields(Funding_Dist)]:\n",
    "    arcpy.AddField_management(Funding_Dist, percentile_field, \"DOUBLE\")\n",
    "\n",
    "# Step 1: Extract values from the source field (ignoring None values)\n",
    "values = []\n",
    "with arcpy.da.SearchCursor(Funding_Dist, [input_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None:  # Exclude None values\n",
    "            values.append(row[0])\n",
    "\n",
    "# Ensure we have at least one valid value\n",
    "if len(values) > 0:\n",
    "    # Step 2: Calculate percentiles as decimals\n",
    "    values = sorted(values)  # Sort values for percentile calculation\n",
    "    percentile_ranks = {value: i / (len(values) - 1) for i, value in enumerate(values)}  # Decimal percentile rank\n",
    "\n",
    "    # Step 3: Update the percentile field\n",
    "    with arcpy.da.UpdateCursor(Funding_Dist, [input_field, percentile_field]) as cursor:\n",
    "        for row in cursor:\n",
    "            if row[0] is not None:  # Check for valid values in CCIpc\n",
    "                # Assign the percentile rank as a decimal, rounded to two decimal places\n",
    "                row[1] = round(percentile_ranks[row[0]], 2)\n",
    "            else:\n",
    "                row[1] = None  # Assign NULL for invalid values (None in CCIpc)\n",
    "            cursor.updateRow(row)\n",
    "\n",
    "    print(f\"CCIpc Percentile values rounded to two decimal places have been calculated and stored in the field '{percentile_field}'.\")\n",
    "else:\n",
    "    print(\"No valid values found in the input field.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCI categories have been calculated and stored in the field 'CCIpcDecile'.\n"
     ]
    }
   ],
   "source": [
    "# CCIpcDecile\n",
    "\n",
    "input_field = \"CCIpc\"\n",
    "category_field = \"CCIpcDecile\" \n",
    "\n",
    "# Add the new category field\n",
    "if category_field not in [f.name for f in arcpy.ListFields(Funding_Dist)]:\n",
    "    arcpy.AddField_management(Funding_Dist, category_field, \"TEXT\", field_length=50)\n",
    "\n",
    "# Step 1: Extract values from the source field\n",
    "values = []\n",
    "with arcpy.da.SearchCursor(Funding_Dist, [input_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None:  # Exclude None values\n",
    "            values.append(row[0])\n",
    "\n",
    "# Step 2: Sort values and define categories\n",
    "values = sorted(values)  # Sort values for decile calculation\n",
    "categories = [\n",
    "    \"Lowest Percentile\",\n",
    "    \">10th-20th Percentile\",\n",
    "    \">20th-30th Percentile\",\n",
    "    \">30th-40th Percentile\",\n",
    "    \">40th-50th Percentile\",\n",
    "    \">50th-60th Percentile\",\n",
    "    \">60th-70th Percentile\",\n",
    "    \">70th-80th Percentile\",\n",
    "    \">80th-90th Percentile\",\n",
    "    \"Highest Percentile\"\n",
    "]\n",
    "\n",
    "# Calculate deciles and map to categories\n",
    "category_mapping = {value: categories[int(i / (len(values) / 10))] for i, value in enumerate(values)}\n",
    "\n",
    "# Step 3: Update the category field\n",
    "with arcpy.da.UpdateCursor(Funding_Dist, [input_field, category_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None:  # Check for valid values in CCIpc\n",
    "            # Assign the appropriate category label\n",
    "            row[1] = category_mapping[row[0]]\n",
    "        else:\n",
    "            row[1] = None  # Assign NULL if CCIpc is None\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(f\"CCI categories have been calculated and stored in the field '{category_field}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCI quartile categories have been calculated and stored in the field 'CCIpcQuartile'.\n"
     ]
    }
   ],
   "source": [
    "# CCIpcQuartile\n",
    "\n",
    "input_field = \"CCIpc\"\n",
    "category_field = \"CCIpcQuartile\"  \n",
    "\n",
    "# Add the new category field if it doesn't exist\n",
    "if category_field not in [f.name for f in arcpy.ListFields(Funding_Dist)]:\n",
    "    arcpy.AddField_management(Funding_Dist, category_field, \"TEXT\", field_length=50) \n",
    "\n",
    "# Step 1: Extract values from the source field\n",
    "values = []\n",
    "with arcpy.da.SearchCursor(Funding_Dist, [input_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None:  # Exclude None values\n",
    "            values.append(row[0])\n",
    "\n",
    "# Step 2: Sort values and define categories for quartiles\n",
    "values = sorted(values)  # Sort values for quartile calculation\n",
    "categories = [\n",
    "    \"Lowest Quartile\",       # 0% to 25%\n",
    "    \">25th-50th Quartile\",   # 25% to 50%\n",
    "    \">50th-75th Quartile\",   # 50% to 75%\n",
    "    \"Highest Quartile\"       # 75% to 100%\n",
    "]\n",
    "\n",
    "# Calculate quartiles and map to categories\n",
    "quartile_mapping = {value: categories[int(i / (len(values) / 4))] for i, value in enumerate(values)}\n",
    "\n",
    "# Step 3: Update the category field\n",
    "with arcpy.da.UpdateCursor(Funding_Dist, [input_field, category_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None:  # Check for valid values in CCIpc\n",
    "            # Assign the appropriate quartile label\n",
    "            row[1] = quartile_mapping[row[0]]\n",
    "        else:\n",
    "            row[1] = None  # Assign NULL if CCIpc is None\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(f\"CCI quartile categories have been calculated and stored in the field '{category_field}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5% range categories have been calculated and stored in the field 'CES4range'.\n"
     ]
    }
   ],
   "source": [
    "# CES4range\n",
    "\n",
    "input_field = \"CIscoreP\"\n",
    "range_field = \"CES4range\" \n",
    "\n",
    "# Add the new range field\n",
    "if range_field not in [f.name for f in arcpy.ListFields(Funding_Dist)]:\n",
    "    arcpy.AddField_management(Funding_Dist, range_field, \"TEXT\", field_length=50) \n",
    "\n",
    "# Step 1: Extract values from the source field\n",
    "values = []\n",
    "with arcpy.da.SearchCursor(Funding_Dist, [input_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None:  # Exclude None values\n",
    "            values.append(row[0])\n",
    "\n",
    "# Step 2: Sort values and define 5% range categories\n",
    "values = sorted(values)  # Sort values\n",
    "categories = [f\"{i * 5}%-{(i + 1) * 5}%\" for i in range(20)]  # 5% ranges from 0% to 100%\n",
    "\n",
    "# Map values to 5% ranges\n",
    "range_mapping = {}\n",
    "bin_size = len(values) / 20  # Divide sorted values into 20 bins (5% each)\n",
    "for i, value in enumerate(values):\n",
    "    range_mapping[value] = categories[int(i // bin_size)]  # Assign range category\n",
    "\n",
    "# Step 3: Update the range field\n",
    "with arcpy.da.UpdateCursor(Funding_Dist, [input_field, range_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None:  # Check for valid values in CIscoreP\n",
    "            # Assign the appropriate range label\n",
    "            row[1] = range_mapping[row[0]]\n",
    "        else:\n",
    "            row[1] = None  # Assign NULL if CIscoreP is None\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(f\"5% range categories have been calculated and stored in the field '{range_field}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% range categories have been calculated and stored in the field 'CES4decile'.\n"
     ]
    }
   ],
   "source": [
    "# CES4decile\n",
    "\n",
    "input_field = \"CIscoreP\"\n",
    "decile_field = \"CES4decile\"  \n",
    "\n",
    "# Add the new decile field \n",
    "if decile_field not in [f.name for f in arcpy.ListFields(Funding_Dist)]:\n",
    "    arcpy.AddField_management(Funding_Dist, decile_field, \"TEXT\", field_length=50)  \n",
    "\n",
    "# Step 1: Extract values from the source field\n",
    "values = []\n",
    "with arcpy.da.SearchCursor(Funding_Dist, [input_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None:  # Exclude None values\n",
    "            values.append(row[0])\n",
    "\n",
    "# Step 2: Sort values and define 10% range categories\n",
    "values = sorted(values)  # Sort values\n",
    "categories = [f\"{i * 10}%-{(i + 1) * 10}%\" for i in range(10)]  # 10% ranges from 0% to 100%\n",
    "\n",
    "# Map values to 10% ranges\n",
    "range_mapping = {}\n",
    "bin_size = len(values) / 10  # Divide sorted values into 10 bins (10% each)\n",
    "for i, value in enumerate(values):\n",
    "    range_mapping[value] = categories[int(i // bin_size)]  # Assign range category\n",
    "\n",
    "# Step 3: Update the decile field\n",
    "with arcpy.da.UpdateCursor(Funding_Dist, [input_field, decile_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None:  # Check for valid values in CIscoreP\n",
    "            # Assign the appropriate decile label\n",
    "            row[1] = range_mapping[row[0]]\n",
    "        else:\n",
    "            row[1] = None  # Assign NULL if CIscoreP is None\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(f\"10% range categories have been calculated and stored in the field '{decile_field}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic categorization completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# PP_simple\n",
    "input_field = \"Designatio\"  \n",
    "output_field = \"PP_simple\" \n",
    "\n",
    "# Add the new field \n",
    "if output_field not in [field.name for field in arcpy.ListFields(Funding_Dist)]:\n",
    "    arcpy.AddField_management(Funding_Dist, output_field, \"TEXT\", field_length=100)\n",
    "\n",
    "# Define the aggregation logic as a dictionary\n",
    "category_mapping = {\n",
    "    \"DAC 1/2 Mile Neighbor: Low-Income Community\": \"DAC 1/2 Mile Neighbor: Low-Income Community\",\n",
    "    \"Low-Income Community\": \"Low-Income Community\",\n",
    "    \"Disadvantaged Community CES\": \"Disadvantaged Community\",\n",
    "    \"Disadvantaged Community CES, Disadvantaged Community Tribal Land, Low-Income Community\": \"Disadvantaged Community\",\n",
    "    \"Disadvantaged Community CES, Low-Income Community\": \"Disadvantaged Community\",\n",
    "    \"Disadvantaged Community Tribal Land\": \"Disadvantaged Community\",\n",
    "    \"Disadvantaged Community Tribal Land, Low-Income Community\": \"Disadvantaged Community\",\n",
    "    \"DAC 1/2 Mile Neighbor: Low-Income Household Eligible\": \"Not a Priority Population Area: Low-Income Households are Eligible\",\n",
    "    \"Not a Priority Population\": \"Not a Priority Population Area: Low-Income Households are Eligible\"\n",
    "}\n",
    "\n",
    "# Update the new field based on the input field's values\n",
    "with arcpy.da.UpdateCursor(Funding_Dist, [input_field, output_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        input_value = row[0]  # Value from the input field\n",
    "        # Determine the category based on the mapping\n",
    "        category = category_mapping.get(input_value, \"Unknown\")  # Default to \"Unknown\" if no match\n",
    "        row[1] = category  # Set the category in the output field\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(\"Demographic categorization completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "# List of fields to delete in preperation for program funding summing\n",
    "\n",
    "fields_to_delete = [\n",
    "    \"Tract_1\", \"TotPop19\", \"Shape_Area_1\"]\n",
    "\n",
    "# Delete fields\n",
    "try:\n",
    "    arcpy.DeleteField_management(Funding_Dist, fields_to_delete)\n",
    "    print(\"Fields deleted successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields have been grouped and summed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create program specific funding fields \n",
    "\n",
    "Funding_Dist = f\"{project_gdb}\\\\Funding_Dist_{suffix}\"\n",
    "\n",
    "# Define groups based on suffixes\n",
    "field_groups = {\n",
    "    \"1\": [\"point_noppggrf_1\", \"point_ppggrf_1\"],\n",
    "    \"2\": [\"point_noppggrf_2\"],\n",
    "    \"3\": [\"point_noppggrf_3\", \"point_ppggrf_3\"],\n",
    "    \"4\": [\"CT_NOPPGGRF_4\", \"CT_PPGGRF_4\"],\n",
    "    \"5\": [\"point_noppggrf_5\", \"point_ppggrf_5\"],\n",
    "    \"7\": [\"point_ppggrf_7\", \"Poly_PPGGRF_7\"],\n",
    "    \"8\": [\"CT_NOPPGGRF_8\", \"CT_PPGGRF_8\"],\n",
    "    \"9\": [\"CT_NOPPGGRF_9\", \"CT_PPGGRF_9\"],\n",
    "    \"10\": [\"point_ppggrf_10\"],\n",
    "    \"11\": [\"point_noppggrf_11\", \"point_ppggrf_11\"],\n",
    "    \"14\": [\"point_noppggrf_14\", \"point_ppggrf_14\"],\n",
    "    \"41\": [\"point_noppggrf_41\", \"point_ppggrf_41\"],\n",
    "    \"45\": [\"point_noppggrf_45\", \"point_ppggrf_45\"],\n",
    "    \"68\": [\"Line_NOPPGGRF_68\", \"Line_PPGGRF_68\", \"point_noppggrf_68\", \"point_ppggrf_68\", \"Poly_NOPPGGRF_68\", \"Poly_PPGGRF_68\"],\n",
    "    \"72\": [\"point_noppggrf_72\"],\n",
    "    \"76\": [\"point_noppggrf_76\", \"point_ppggrf_76\"],\n",
    "    \"78\": [\"Line_NOPPGGRF_78\", \"Line_PPGGRF_78\", \"point_noppggrf_78\", \"point_ppggrf_78\", \"Poly_NOPPGGRF_78\", \"Poly_PPGGRF_78\"],\n",
    "    \"80\": [\"CT_NOPPGGRF_80\", \"CT_PPGGRF_80\"],\n",
    "    \"82\": [\"CT_NOPPGGRF_82\", \"CT_PPGGRF_82\"],\n",
    "    \"86\": [\"point_noppggrf_86\", \"point_ppggrf_86\", \"Poly_NOPPGGRF_86\"],\n",
    "    \"88\": [\"CT_NOPPGGRF_88\", \"CT_PPGGRF_88\"],\n",
    "    \"90\": [\"CT_NOPPGGRF_90\", \"CT_PPGGRF_90\"],\n",
    "    \"120\": [\"point_ppggrf_120\"],\n",
    "    \"124\": [\"point_noppggrf_124\", \"point_ppggrf_124\"],\n",
    "    \"128\": [\"CT_NOPPGGRF_128\", \"CT_PPGGRF_128\"],\n",
    "    \"130\": [\"point_ppggrf_130\"],\n",
    "    \"132\": [\"point_noppggrf_132\", \"point_ppggrf_132\"],\n",
    "    \"134\": [\"point_noppggrf_134\", \"point_ppggrf_134\"],\n",
    "    \"136\": [\"point_noppggrf_136\", \"point_ppggrf_136\"],\n",
    "    \"138\": [\"point_noppggrf_138\", \"point_ppggrf_138\"],\n",
    "    \"142\": [\"point_noppggrf_142\", \"point_ppggrf_142\"],\n",
    "    \"148\": [\"point_noppggrf_148\", \"point_ppggrf_148\"],\n",
    "    \"189\": [\"Poly_PPGGRF_189\"],\n",
    "    \"191\": [\"point_noppggrf_191\", \"point_ppggrf_191\"],\n",
    "    \"193\": [\"point_noppggrf_193\", \"point_ppggrf_193\"],\n",
    "    \"235\": [\"point_noppggrf_235\", \"point_ppggrf_235\"],\n",
    "    \"237\": [\"point_noppggrf_237\", \"point_ppggrf_237\"],\n",
    "    \"239\": [\"point_noppggrf_239\", \"point_ppggrf_239\"],\n",
    "    \"243\": [\"point_noppggrf_243\"],\n",
    "    \"245\": [\"point_noppggrf_245\", \"point_ppggrf_245\"],\n",
    "    \"247\": [\"point_noppggrf_247\", \"point_ppggrf_247\"],\n",
    "    \"249\": [\"point_noppggrf_249\"],\n",
    "    \"251\": [\"Poly_NOPPGGRF_251\", \"Poly_PPGGRF_251\", \"point_noppggrf_251\", \"point_ppggrf_251\"],\n",
    "    \"253\": [\"point_noppggrf_253\", \"point_ppggrf_253\"],\n",
    "    \"255\": [\"point_noppggrf_255\"],\n",
    "    \"257\": [\"point_noppggrf_257\", \"point_ppggrf_257\"],\n",
    "    \"259\": [\"point_noppggrf_259\", \"point_ppggrf_259\"],\n",
    "    \"261\": [\"point_noppggrf_261\", \"point_ppggrf_261\"],\n",
    "    \"263\": [\"point_noppggrf_263\", \"point_ppggrf_263\"],\n",
    "    \"265\": [\"Poly_NOPPGGRF_265\", \"Poly_PPGGRF_265\", \"point_noppggrf_265\", \"point_ppggrf_265\"],\n",
    "    \"267\": [\"point_ppggrf_267\"],\n",
    "    \"269\": [\"point_ppggrf_269\"],\n",
    "    \"271\": [\"point_ppggrf_271\"],\n",
    "    \"329\": [\"CT_PPGGRF_329\"],\n",
    "    \"331\": [\"point_noppggrf_331\"],\n",
    "    \"333\": [\"point_noppggrf_333\", \"point_ppggrf_333\"],\n",
    "    \"335\": [\"point_noppggrf_335\", \"point_ppggrf_335\"],\n",
    "    \"337\": [\"CT_NOPPGGRF_337\", \"CT_PPGGRF_337\"],\n",
    "    \"339\": [\"point_noppggrf_339\", \"point_ppggrf_339\"],\n",
    "    \"341\": [\"point_noppggrf_341\", \"point_ppggrf_341\"],\n",
    "    \"345\": [\"point_ppggrf_345\"], \n",
    "    \"471\": [\"point_noppggrf_471\", \"point_ppggrf_471\"],\n",
    "    \"475\": [\"point_noppggrf_475\", \"point_ppggrf_475\"],\n",
    "    \"477\": [\"point_noppggrf_477\"],\n",
    "    \"479\": [\"point_noppggrf_479\", \"point_ppggrf_479\"],\n",
    "    \"547\": [\"point_noppggrf_547\", \"point_ppggrf_547\"],\n",
    "    \"549\": [\"point_noppggrf_549\", \"point_ppggrf_549\"],\n",
    "    \"613\": [\"point_noppggrf_613\", \"point_ppggrf_613\"],\n",
    "    \"615\": [\"point_noppggrf_615\"],\n",
    "    \"617\": [\"point_noppggrf_617\"],\n",
    "    \"619\": [\"point_noppggrf_619\", \"point_ppggrf_619\"],\n",
    "    \"621\": [\"point_noppggrf_621\", \"point_ppggrf_621\"],\n",
    "    \"690\": [\"point_noppggrf_690\", \"point_ppggrf_690\"],\n",
    "    \"695\": [\"point_ppggrf_695\", \"Poly_PPGGRF_695\"],\n",
    "    \"765\": [\"point_noppggrf_765\", \"point_ppggrf_765\"],\n",
    "    \"837\": [\"CT_PPGGRF_837\"],\n",
    "    \"839\": [\"point_noppggrf_839\"],\n",
    "    \"981\": [\"point_noppggrf_981\"]}\n",
    "\n",
    "# Add a field for each group and calculate the sum of the grouped fields\n",
    "for group, fields in field_groups.items():\n",
    "    # Add a new field for the summed value of each group\n",
    "    new_field_name = f\"sum_group_{group}\"\n",
    "    arcpy.AddField_management(Funding_Dist, new_field_name, \"DOUBLE\")\n",
    "    \n",
    "    # Use an update cursor to calculate the sum for each record\n",
    "    with arcpy.da.UpdateCursor(Funding_Dist, fields + [new_field_name]) as cursor:\n",
    "        for row in cursor:\n",
    "            # Sum the values of the fields in the group\n",
    "            total_sum = sum([row[fields.index(field)] if row[fields.index(field)] is not None else 0 for field in fields])\n",
    "            row[-1] = total_sum  # Assign the sum to the new field\n",
    "            cursor.updateRow(row)\n",
    "\n",
    "print(\"Fields have been grouped and summed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Program and GGRF Totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total sum of all summed calculated program fields is: 11,011,906,653\n"
     ]
    }
   ],
   "source": [
    "# Check sum of all program funding from calculated fields\n",
    "\n",
    "program_sum_fields = [\"sum_group_1\", \"sum_group_2\", \"sum_group_3\", \"sum_group_4\", \"sum_group_5\", \"sum_group_7\", \"sum_group_8\", \"sum_group_9\", \n",
    "          \"sum_group_10\", \"sum_group_11\", \"sum_group_14\", \"sum_group_41\", \"sum_group_45\", \"sum_group_68\", \"sum_group_72\", \"sum_group_76\", \n",
    "          \"sum_group_78\", \"sum_group_80\", \"sum_group_82\", \"sum_group_86\", \"sum_group_88\", \"sum_group_90\", \"sum_group_120\", \"sum_group_124\", \n",
    "          \"sum_group_128\", \"sum_group_130\", \"sum_group_132\", \"sum_group_134\", \"sum_group_136\", \"sum_group_138\", \"sum_group_142\", \"sum_group_148\",\n",
    "          \"sum_group_189\", \"sum_group_191\", \"sum_group_193\", \"sum_group_235\", \"sum_group_237\", \"sum_group_239\", \"sum_group_243\", \"sum_group_245\", \n",
    "          \"sum_group_247\", \"sum_group_249\", \"sum_group_251\", \"sum_group_253\", \"sum_group_255\", \"sum_group_257\", \"sum_group_259\", \n",
    "          \"sum_group_261\", \"sum_group_263\", \"sum_group_265\", \"sum_group_267\", \"sum_group_269\", \"sum_group_271\", \"sum_group_329\", \n",
    "          \"sum_group_331\", \"sum_group_333\", \"sum_group_335\", \"sum_group_337\", \"sum_group_339\", \"sum_group_341\", \"sum_group_345\",\n",
    "          \"sum_group_471\", \"sum_group_475\", \"sum_group_477\", \"sum_group_479\", \"sum_group_547\", \"sum_group_549\", \"sum_group_613\", \n",
    "          \"sum_group_615\", \"sum_group_617\", \"sum_group_619\", \"sum_group_621\", \"sum_group_690\", \"sum_group_695\", \"sum_group_765\",\n",
    "          \"sum_group_837\", \"sum_group_839\", \"sum_group_981\"]\n",
    "\n",
    "\n",
    "# Initialize a total variable for all fields\n",
    "total_sum = 0\n",
    "\n",
    "# Use a SearchCursor to iterate through the field values\n",
    "with arcpy.da.SearchCursor(Funding_Dist, program_sum_fields) as cursor:\n",
    "    for row in cursor:\n",
    "        for value in row:\n",
    "            if value is not None:  # Ensure the value is not NULL\n",
    "                total_sum += value\n",
    "\n",
    "# Round and print the result\n",
    "total_sum = round(total_sum)\n",
    "print(f\"The total sum of all summed calculated program fields is: {total_sum:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total sum of all summed input program fields is: 11,011,906,653\n"
     ]
    }
   ],
   "source": [
    "# Check sum of all program funding from the input data fields (to check against the total from calculated fields above)\n",
    "\n",
    "fields = [\"CT_NOPPGGRF_128\", \"CT_NOPPGGRF_337\", \"CT_NOPPGGRF_4\", \"CT_NOPPGGRF_8\", \"CT_NOPPGGRF_80\", \"CT_NOPPGGRF_82\", \n",
    "          \"CT_NOPPGGRF_88\", \"CT_NOPPGGRF_9\", \"CT_NOPPGGRF_90\", \"CT_PPGGRF_128\", \"CT_PPGGRF_329\", \"CT_PPGGRF_337\", \"CT_PPGGRF_4\", \n",
    "          \"CT_PPGGRF_8\", \"CT_PPGGRF_80\", \"CT_PPGGRF_82\", \"CT_PPGGRF_837\", \"CT_PPGGRF_88\", \"CT_PPGGRF_9\", \"CT_PPGGRF_90\", \n",
    "          \"Line_NOPPGGRF_68\", \"Line_NOPPGGRF_78\", \"Line_PPGGRF_68\", \"Line_PPGGRF_78\", \"point_noppggrf_1\", \"point_noppggrf_11\", \n",
    "          \"point_noppggrf_124\", \"point_noppggrf_132\", \"point_noppggrf_134\", \"point_noppggrf_136\", \"point_noppggrf_138\", \n",
    "          \"point_noppggrf_14\", \"point_noppggrf_142\", \"point_noppggrf_148\", \"point_noppggrf_191\", \"point_noppggrf_193\",\n",
    "          \"point_noppggrf_2\", \"point_noppggrf_235\", \"point_noppggrf_237\", \"point_noppggrf_239\", \"point_noppggrf_243\", \n",
    "          \"point_noppggrf_245\", \"point_noppggrf_247\", \"point_noppggrf_249\", \"point_noppggrf_251\", \"point_noppggrf_253\", \n",
    "          \"point_noppggrf_255\", \"point_noppggrf_257\", \"point_noppggrf_259\", \"point_noppggrf_261\", \"point_noppggrf_263\", \n",
    "          \"point_noppggrf_265\", \"point_noppggrf_3\", \"point_noppggrf_331\", \"point_noppggrf_333\", \"point_noppggrf_335\", \n",
    "          \"point_noppggrf_339\", \"point_noppggrf_341\", \"point_noppggrf_41\", \"point_noppggrf_45\", \"point_noppggrf_471\", \n",
    "          \"point_noppggrf_475\", \"point_noppggrf_477\", \"point_noppggrf_479\", \"point_noppggrf_5\", \"point_noppggrf_547\", \n",
    "          \"point_noppggrf_549\", \"point_noppggrf_613\", \"point_noppggrf_615\", \"point_noppggrf_617\", \"point_noppggrf_619\", \n",
    "          \"point_noppggrf_621\", \"point_noppggrf_68\", \"point_noppggrf_690\", \"point_noppggrf_72\", \"point_noppggrf_76\", \n",
    "          \"point_noppggrf_765\", \"point_noppggrf_78\", \"point_noppggrf_839\", \"point_noppggrf_86\", \"point_noppggrf_981\", \n",
    "          \"point_ppggrf_1\", \"point_ppggrf_10\", \"point_ppggrf_11\", \"point_ppggrf_120\", \"point_ppggrf_124\", \n",
    "          \"point_ppggrf_130\", \"point_ppggrf_132\", \"point_ppggrf_134\", \"point_ppggrf_136\", \"point_ppggrf_138\", \n",
    "          \"point_ppggrf_14\", \"point_ppggrf_142\", \"point_ppggrf_148\", \"point_ppggrf_191\", \"point_ppggrf_193\", \n",
    "          \"point_ppggrf_235\", \"point_ppggrf_237\", \"point_ppggrf_239\", \"point_ppggrf_245\", \"point_ppggrf_247\",\n",
    "          \"point_ppggrf_251\", \"point_ppggrf_253\", \"point_ppggrf_257\", \"point_ppggrf_259\", \"point_ppggrf_261\", \n",
    "          \"point_ppggrf_263\", \"point_ppggrf_265\", \"point_ppggrf_267\", \"point_ppggrf_269\", \"point_ppggrf_271\",\n",
    "          \"point_ppggrf_3\", \"point_ppggrf_333\", \"point_ppggrf_335\", \"point_ppggrf_339\", \"point_ppggrf_341\", \n",
    "          \"point_ppggrf_345\", \"point_ppggrf_41\", \"point_ppggrf_45\", \"point_ppggrf_471\", \"point_ppggrf_475\",\n",
    "          \"point_ppggrf_479\", \"point_ppggrf_5\", \"point_ppggrf_547\", \"point_ppggrf_549\", \"point_ppggrf_613\",\n",
    "          \"point_ppggrf_619\", \"point_ppggrf_621\", \"point_ppggrf_68\", \"point_ppggrf_690\", \"point_ppggrf_695\",\n",
    "          \"point_ppggrf_7\", \"point_ppggrf_76\", \"point_ppggrf_765\", \"point_ppggrf_78\", \"point_ppggrf_86\", \n",
    "          \"Poly_NOPPGGRF_251\", \"Poly_NOPPGGRF_265\", \"Poly_NOPPGGRF_68\", \"Poly_NOPPGGRF_78\", \"Poly_NOPPGGRF_86\", \n",
    "          \"Poly_PPGGRF_189\", \"Poly_PPGGRF_251\", \"Poly_PPGGRF_265\", \"Poly_PPGGRF_68\", \"Poly_PPGGRF_695\", \"Poly_PPGGRF_7\",\n",
    "          \"Poly_PPGGRF_78\"]\n",
    "\n",
    "\n",
    "# Initialize a total variable for all fields\n",
    "total_sum = 0\n",
    "\n",
    "# Use a SearchCursor to iterate through the field values\n",
    "with arcpy.da.SearchCursor(Funding_Dist, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        for value in row:\n",
    "            if value is not None:  # Ensure the value is not NULL\n",
    "                total_sum += value\n",
    "\n",
    "# Round and print the result\n",
    "total_sum = round(total_sum)\n",
    "print(f\"The total sum of all summed input program fields is: {total_sum:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total summed calculated GGRF field 'GGRF' is: 11,011,786,903\n",
      "The total summed calculated GGRF field 'PPGGRF' is: 7,605,701,813\n",
      "The total summed calculated GGRF field 'NOPPGGRF' is: 3,406,085,090\n"
     ]
    }
   ],
   "source": [
    "# Calculate SUM of GGRF totals (to check against above program total)\n",
    "\n",
    "# List of fields to sum\n",
    "fields = [\"GGRF\", \"PPGGRF\", \"NOPPGGRF\"]\n",
    "\n",
    "# Initialize a dictionary to store totals\n",
    "totals = {field: 0 for field in fields}\n",
    "\n",
    "# Use a SearchCursor to iterate through the field values\n",
    "with arcpy.da.SearchCursor(Funding_Dist, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        for field, value in zip(fields, row):\n",
    "            if value is not None:  # Ensure the value is not NULL\n",
    "                totals[field] += value\n",
    "\n",
    "# Print results\n",
    "for field, total in totals.items():\n",
    "    total = round(total)\n",
    "    print(f\"The total summed calculated GGRF field '{field}' is: {total:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total summed calculated NOPPGGRF field is: 3,406,085,090\n",
      "The total summed calculated PPGGRF field is: 7,605,701,813\n",
      "The total summed calculated GGRF field is: 11,011,786,903\n"
     ]
    }
   ],
   "source": [
    "# Calculate the SUM of GGRF input fields (to check agaisnt calculated GGRF totals above)\n",
    "\n",
    "# Define field categories\n",
    "NOPPGGRF_fields = [\"point_noppggrf_total\", \"Poly_NOPPGGRF_TOTAL\", \"CT_NOPPGGRF_TOTAL\", \"Line_NOPPGGRF_TOTAL\"]\n",
    "PPGGRF_fields = [\"point_ppggrf_total\", \"Poly_PPGGRF_TOTAL\", \"CT_PPGGRF_TOTAL\", \"Line_PPGGRF_TOTAL\"]\n",
    "GGRF_fields = [\"point_ggrf_total\", \"Poly_GGRF_TOTAL\", \"CT_GGRF_TOTAL\", \"Line_GGRF_TOTAL\"]\n",
    "\n",
    "# Dictionary to store totals\n",
    "totals = {\"NOPPGGRF\": 0, \"PPGGRF\": 0, \"GGRF\": 0}\n",
    "\n",
    "# Sum values for each category\n",
    "for category, fields in zip(totals.keys(), [NOPPGGRF_fields, PPGGRF_fields, GGRF_fields]):\n",
    "    with arcpy.da.SearchCursor(Funding_Dist, fields) as cursor:\n",
    "        for row in cursor:\n",
    "            for value in row:\n",
    "                if value is not None:  # Ensure value is not NULL\n",
    "                    totals[category] += value\n",
    "\n",
    "# Print results\n",
    "for category, total in totals.items():\n",
    "    total = round(total)\n",
    "    print(f\"The total summed calculated {category} field is: {total:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalize fields to include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "# delete unneeded fields\n",
    "\n",
    "# List of fields to delete\n",
    "fields_to_delete = [\n",
    "    \"ApproxLoc\", \"Shape_Leng\", \"ExclCTdata4GIS_ExclCTdata\",\n",
    "    \"CT_NOPPGGRF_4\", \"CT_NOPPGGRF_8\", \"CT_NOPPGGRF_9\", \"CT_NOPPGGRF_80\", \"CT_NOPPGGRF_82\",\n",
    "    \"CT_NOPPGGRF_88\", \"CT_NOPPGGRF_90\", \"CT_NOPPGGRF_128\", \"CT_NOPPGGRF_337\", \"CT_PPGGRF_4\",\n",
    "    \"CT_PPGGRF_8\", \"CT_PPGGRF_9\", \"CT_PPGGRF_80\", \"CT_PPGGRF_82\", \"CT_PPGGRF_88\", \"CT_PPGGRF_90\",\n",
    "    \"CT_PPGGRF_128\", \"CT_PPGGRF_329\", \"CT_PPGGRF_337\", \"CT_PPGGRF_837\", \"FID_CES4PP_ctAR24\",\n",
    "    \"Poly_NOPPGGRF_68\", \"Poly_NOPPGGRF_78\", \"Poly_NOPPGGRF_86\", \"Poly_NOPPGGRF_251\", \"Poly_NOPPGGRF_265\",\n",
    "    \"Poly_PPGGRF_7\", \"Poly_PPGGRF_68\", \"Poly_PPGGRF_78\", \"Poly_PPGGRF_189\", \"Poly_PPGGRF_251\",\n",
    "    \"Poly_PPGGRF_265\", \"Poly_PPGGRF_695\", \"point_noppggrf_1\", \"point_noppggrf_2\", \"point_noppggrf_3\",\n",
    "    \"point_noppggrf_5\", \"point_noppggrf_11\", \"point_noppggrf_14\", \"point_noppggrf_41\", \"point_noppggrf_45\",\n",
    "    \"point_noppggrf_68\", \"point_noppggrf_72\", \"point_noppggrf_76\", \"point_noppggrf_78\", \"point_noppggrf_86\",\n",
    "    \"point_noppggrf_124\", \"point_noppggrf_132\", \"point_noppggrf_134\", \"point_noppggrf_136\", \"point_noppggrf_138\",\n",
    "    \"point_noppggrf_142\", \"point_noppggrf_148\", \"point_noppggrf_191\", \"point_noppggrf_193\", \"point_noppggrf_235\",\n",
    "    \"point_noppggrf_237\", \"point_noppggrf_239\", \"point_noppggrf_243\", \"point_noppggrf_245\", \"point_noppggrf_247\",\n",
    "    \"point_noppggrf_249\", \"point_noppggrf_251\", \"point_noppggrf_253\", \"point_noppggrf_255\", \"point_noppggrf_257\",\n",
    "    \"point_noppggrf_259\", \"point_noppggrf_261\", \"point_noppggrf_263\", \"point_noppggrf_265\", \"point_noppggrf_331\",\n",
    "    \"point_noppggrf_333\", \"point_noppggrf_335\", \"point_noppggrf_339\", \"point_noppggrf_341\", \"point_noppggrf_471\",\n",
    "    \"point_noppggrf_475\", \"point_noppggrf_477\", \"point_noppggrf_479\", \"point_noppggrf_547\", \"point_noppggrf_549\",\n",
    "    \"point_noppggrf_613\", \"point_noppggrf_615\", \"point_noppggrf_617\", \"point_noppggrf_619\", \"point_noppggrf_621\",\n",
    "    \"point_noppggrf_690\", \"point_noppggrf_765\", \"point_noppggrf_839\", \"point_noppggrf_981\", \"point_ppggrf_1\",\n",
    "    \"point_ppggrf_3\", \"point_ppggrf_5\", \"point_ppggrf_7\", \"point_ppggrf_10\", \"point_ppggrf_11\", \"point_ppggrf_14\",\n",
    "    \"point_ppggrf_41\", \"point_ppggrf_45\", \"point_ppggrf_68\", \"point_ppggrf_76\", \"point_ppggrf_78\", \"point_ppggrf_86\",\n",
    "    \"point_ppggrf_120\", \"point_ppggrf_124\", \"point_ppggrf_130\", \"point_ppggrf_132\", \"point_ppggrf_134\",\n",
    "    \"point_ppggrf_136\", \"point_ppggrf_138\", \"point_ppggrf_142\", \"point_ppggrf_148\", \"point_ppggrf_191\",\n",
    "    \"point_ppggrf_193\", \"point_ppggrf_235\", \"point_ppggrf_237\", \"point_ppggrf_239\", \"point_ppggrf_245\",\n",
    "    \"point_ppggrf_247\", \"point_ppggrf_251\", \"point_ppggrf_253\", \"point_ppggrf_257\", \"point_ppggrf_259\",\n",
    "    \"point_ppggrf_261\", \"point_ppggrf_263\", \"point_ppggrf_265\", \"point_ppggrf_267\", \"point_ppggrf_269\",\n",
    "    \"point_ppggrf_271\", \"point_ppggrf_333\", \"point_ppggrf_335\", \"point_ppggrf_339\", \"point_ppggrf_341\",\n",
    "    \"point_ppggrf_345\", \"point_ppggrf_471\", \"point_ppggrf_475\", \"point_ppggrf_479\", \"point_ppggrf_547\",\n",
    "    \"point_ppggrf_549\", \"point_ppggrf_613\", \"point_ppggrf_619\", \"point_ppggrf_621\", \"point_ppggrf_690\",\n",
    "    \"point_ppggrf_695\", \"point_ppggrf_765\", \"Point_Count\", \"Line_OBJECTID\", \"Line_NOPPGGRF_68\", \"Line_NOPPGGRF_78\",\n",
    "    \"Line_PPGGRF_68\", \"Line_PPGGRF_78\"\n",
    "]\n",
    "\n",
    "# Delete fields\n",
    "try:\n",
    "    arcpy.DeleteField_management(Funding_Dist, fields_to_delete)\n",
    "    print(\"Fields deleted successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save 'wide' version of the feature layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature class copied successfully to C:\\Users\\gcowan\\Documents\\ArcGIS\\Projects\\Distribution Analysis\\Data Restructure\\Data_Restructure\\Data_Restructure.gdb\\Funding_Dist_AR24_wide\n"
     ]
    }
   ],
   "source": [
    "# Path to save the 'wide' version of the feature class\n",
    "Funding_Dist_wide = f\"{project_gdb}\\\\Funding_Dist_{suffix}_wide\"\n",
    "\n",
    "# Step 1: Create a copy of the feature class\n",
    "try:\n",
    "    arcpy.CopyFeatures_management(Funding_Dist, Funding_Dist_wide)\n",
    "    print(f\"Feature class copied successfully to {Funding_Dist_wide}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while copying the feature class: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 'Long' File Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ID field 'UniqueID_wide' added and populated successfully.\n"
     ]
    }
   ],
   "source": [
    "# add a unique ID to the 'wide' version of the file \n",
    "\n",
    "# Add a new field for the unique ID\n",
    "unique_id_field = \"UniqueID_wide\"\n",
    "arcpy.management.AddField(Funding_Dist, unique_id_field, \"LONG\")\n",
    "\n",
    "# Calculate the unique ID based on OBJECTID\n",
    "arcpy.management.CalculateField(Funding_Dist, unique_id_field, \"!OBJECTID!\", \"PYTHON3\")\n",
    "\n",
    "print(f\"Unique ID field '{unique_id_field}' added and populated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restructuring completed.\n"
     ]
    }
   ],
   "source": [
    "# Path to save the 'long' version of the feature class\n",
    "Funding_Dist_long = f\"{project_gdb}\\\\Funding_Dist_{suffix}_long\"\n",
    "\n",
    "# List of funding columns\n",
    "funding_columns = [\"sum_group_1\", \"sum_group_2\", \"sum_group_3\", \"sum_group_4\", \"sum_group_5\", \"sum_group_7\", \"sum_group_8\", \"sum_group_9\", \n",
    "          \"sum_group_10\", \"sum_group_11\", \"sum_group_14\", \"sum_group_41\", \"sum_group_45\", \"sum_group_68\", \"sum_group_72\", \"sum_group_76\", \n",
    "          \"sum_group_78\", \"sum_group_80\", \"sum_group_82\", \"sum_group_86\", \"sum_group_88\", \"sum_group_90\", \"sum_group_120\", \"sum_group_124\", \n",
    "          \"sum_group_128\", \"sum_group_130\", \"sum_group_132\", \"sum_group_134\", \"sum_group_136\", \"sum_group_138\", \"sum_group_142\", \"sum_group_148\",\n",
    "          \"sum_group_189\", \"sum_group_191\", \"sum_group_193\", \"sum_group_235\", \"sum_group_237\", \"sum_group_239\", \"sum_group_243\", \"sum_group_245\", \n",
    "          \"sum_group_247\", \"sum_group_249\", \"sum_group_251\", \"sum_group_253\", \"sum_group_255\", \"sum_group_257\", \"sum_group_259\", \n",
    "          \"sum_group_261\", \"sum_group_263\", \"sum_group_265\", \"sum_group_267\", \"sum_group_269\", \"sum_group_271\", \"sum_group_329\", \n",
    "          \"sum_group_331\", \"sum_group_333\", \"sum_group_335\", \"sum_group_337\", \"sum_group_339\", \"sum_group_341\", \"sum_group_345\",\n",
    "          \"sum_group_471\", \"sum_group_475\", \"sum_group_477\", \"sum_group_479\", \"sum_group_547\", \"sum_group_549\", \"sum_group_613\", \n",
    "          \"sum_group_615\", \"sum_group_617\", \"sum_group_619\", \"sum_group_621\", \"sum_group_690\", \"sum_group_695\", \"sum_group_765\",\n",
    "          \"sum_group_837\", \"sum_group_839\", \"sum_group_981\"]\n",
    "\n",
    "# Get all the fields in the input shapefile\n",
    "all_fields = [f.name for f in arcpy.ListFields(Funding_Dist) if f.type not in (\"Geometry\", \"OID\")]\n",
    "\n",
    "# Create a copy of the input feature class\n",
    "arcpy.management.CopyFeatures(Funding_Dist, Funding_Dist_long)\n",
    "\n",
    "# Add new fields to the output shapefile\n",
    "arcpy.AddField_management(Funding_Dist_long, 'Program_Column', 'TEXT', field_length=100)\n",
    "arcpy.AddField_management(Funding_Dist_long, 'Funding_Amount', 'DOUBLE')\n",
    "\n",
    "# Open an InsertCursor for the output feature class\n",
    "with arcpy.da.InsertCursor(Funding_Dist_long, all_fields + ['Program_Column', 'Funding_Amount', 'SHAPE@']) as insert_cursor:\n",
    "    # Open a SearchCursor to iterate through the input shapefile\n",
    "    with arcpy.da.SearchCursor(Funding_Dist, all_fields + funding_columns + ['SHAPE@']) as search_cursor:\n",
    "        for row in search_cursor:\n",
    "            # Extract values for fields that should remain unchanged\n",
    "            original_values = list(row[:len(all_fields)])\n",
    "            geometry = row[-1]  # Extract the geometry\n",
    "            \n",
    "            # Iterate through each funding column\n",
    "            for idx, funding_column in enumerate(funding_columns, start=len(all_fields)):\n",
    "                funding_amount = row[idx]  # Access the funding amount from the corresponding column\n",
    "                \n",
    "                # Insert a new row if the funding amount is greater than 0\n",
    "                if funding_amount > 0:\n",
    "                    insert_cursor.insertRow(original_values + [funding_column, funding_amount, geometry])\n",
    "\n",
    "print(\"Restructuring completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted column: sum_group_1\n",
      "Deleted column: sum_group_2\n",
      "Deleted column: sum_group_3\n",
      "Deleted column: sum_group_4\n",
      "Deleted column: sum_group_5\n",
      "Deleted column: sum_group_7\n",
      "Deleted column: sum_group_8\n",
      "Deleted column: sum_group_9\n",
      "Deleted column: sum_group_10\n",
      "Deleted column: sum_group_11\n",
      "Deleted column: sum_group_14\n",
      "Deleted column: sum_group_41\n",
      "Deleted column: sum_group_45\n",
      "Deleted column: sum_group_68\n",
      "Deleted column: sum_group_72\n",
      "Deleted column: sum_group_76\n",
      "Deleted column: sum_group_78\n",
      "Deleted column: sum_group_80\n",
      "Deleted column: sum_group_82\n",
      "Deleted column: sum_group_86\n",
      "Deleted column: sum_group_88\n",
      "Deleted column: sum_group_90\n",
      "Deleted column: sum_group_120\n",
      "Deleted column: sum_group_124\n",
      "Deleted column: sum_group_128\n",
      "Deleted column: sum_group_130\n",
      "Deleted column: sum_group_132\n",
      "Deleted column: sum_group_134\n",
      "Deleted column: sum_group_136\n",
      "Deleted column: sum_group_138\n",
      "Deleted column: sum_group_142\n",
      "Deleted column: sum_group_148\n",
      "Deleted column: sum_group_189\n",
      "Deleted column: sum_group_191\n",
      "Deleted column: sum_group_193\n",
      "Deleted column: sum_group_235\n",
      "Deleted column: sum_group_237\n",
      "Deleted column: sum_group_239\n",
      "Deleted column: sum_group_243\n",
      "Deleted column: sum_group_245\n",
      "Deleted column: sum_group_247\n",
      "Deleted column: sum_group_249\n",
      "Deleted column: sum_group_251\n",
      "Deleted column: sum_group_253\n",
      "Deleted column: sum_group_255\n",
      "Deleted column: sum_group_257\n",
      "Deleted column: sum_group_259\n",
      "Deleted column: sum_group_261\n",
      "Deleted column: sum_group_263\n",
      "Deleted column: sum_group_265\n",
      "Deleted column: sum_group_267\n",
      "Deleted column: sum_group_269\n",
      "Deleted column: sum_group_271\n",
      "Deleted column: sum_group_329\n",
      "Deleted column: sum_group_331\n",
      "Deleted column: sum_group_333\n",
      "Deleted column: sum_group_335\n",
      "Deleted column: sum_group_337\n",
      "Deleted column: sum_group_339\n",
      "Deleted column: sum_group_341\n",
      "Deleted column: sum_group_345\n",
      "Deleted column: sum_group_471\n",
      "Deleted column: sum_group_475\n",
      "Deleted column: sum_group_477\n",
      "Deleted column: sum_group_479\n",
      "Deleted column: sum_group_547\n",
      "Deleted column: sum_group_549\n",
      "Deleted column: sum_group_613\n",
      "Deleted column: sum_group_615\n",
      "Deleted column: sum_group_617\n",
      "Deleted column: sum_group_619\n",
      "Deleted column: sum_group_621\n",
      "Deleted column: sum_group_690\n",
      "Deleted column: sum_group_695\n",
      "Deleted column: sum_group_765\n",
      "Deleted column: sum_group_837\n",
      "Deleted column: sum_group_839\n",
      "Deleted column: sum_group_981\n",
      "All specified funding columns have been processed.\n"
     ]
    }
   ],
   "source": [
    "# Delete the individual funding columns\n",
    "for column in funding_columns:\n",
    "    if arcpy.ListFields(Funding_Dist_long, column): \n",
    "        arcpy.DeleteField_management(Funding_Dist_long, column)\n",
    "        print(f\"Deleted column: {column}\")\n",
    "    else:\n",
    "        print(f\"Column not found (skipped): {column}\")\n",
    "\n",
    "print(\"All specified funding columns have been processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with null values in Program_Column have been deleted.\n"
     ]
    }
   ],
   "source": [
    "# Open an UpdateCursor to delete rows that have multiple inputs in program funding columns\n",
    "with arcpy.da.UpdateCursor(Funding_Dist_long, ['Program_Column']) as cursor:\n",
    "    for row in cursor:\n",
    "        # Check if Program_Column is null or empty\n",
    "        if row[0] is None or row[0] == \"\":\n",
    "            cursor.deleteRow()\n",
    "\n",
    "print(\"Rows with null values in Program_Column have been deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic range fields updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Demographic percentage columns\n",
    "demographic_columns = [\"Hispanic\", \"White\", \"AfricanAm\", \"NativeAm\", \"OtherMult\", \"PctBIPOC\", \"AAPI\"]\n",
    "\n",
    "# Add new fields to hold the range label for each demographic column\n",
    "for column in demographic_columns:\n",
    "    range_field_name = f\"{column}_Range\"\n",
    "    arcpy.AddField_management(Funding_Dist_long, range_field_name, \"TEXT\", field_length=20)\n",
    "\n",
    "# Populate the new fields with the appropriate range label\n",
    "with arcpy.da.UpdateCursor(Funding_Dist_long, demographic_columns + [f\"{col}_Range\" for col in demographic_columns]) as cursor:\n",
    "    for row in cursor:\n",
    "        for col_index, column in enumerate(demographic_columns):\n",
    "            percent_value = row[col_index]\n",
    "            if percent_value is not None:\n",
    "                # Determine the range the value falls into\n",
    "                for i in range(1, 11):\n",
    "                    range_start = (i - 1) * 10\n",
    "                    range_end = i * 10\n",
    "                    if range_start <= percent_value < range_end or (i == 10 and percent_value == 100): \n",
    "                        range_label = f\"{range_start}-{range_end}%\"\n",
    "                        range_field_index = len(demographic_columns) + col_index\n",
    "                        row[range_field_index] = range_label\n",
    "                        break\n",
    "            else:\n",
    "                # If the value is None, leave the range field blank\n",
    "                range_field_index = len(demographic_columns) + col_index\n",
    "                row[range_field_index] = None\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(\"Demographic range fields updated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program_Column values renamed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Map old names in Program_Column to new descriptive names\n",
    "column_mapping = {\n",
    "    \"sum_group_1\": \"Dairy Digester Research and Development Program\",\n",
    "    \"sum_group_2\": \"Renewable and Alternative Fuels\",\n",
    "    \"sum_group_3\": \"State Water Efficiency and Enhancement Program\",\n",
    "    \"sum_group_4\": \"Clean Vehicle Rebate Project\",\n",
    "    \"sum_group_5\": \"Clean Truck and Bus Vouchers (HVIP)\",\n",
    "    \"sum_group_7\": \"Clean Mobility Options\",\n",
    "    \"sum_group_8\": \"Clean Cars 4 All\",\n",
    "    \"sum_group_9\": \"Financing Assistance for Lower-Income Consumers\",\n",
    "    \"sum_group_10\": \"Advanced Technology Demonstration and Pilot Projects\",\n",
    "    \"sum_group_11\": \"Zero-Emission Truck and Bus Pilot\",\n",
    "    \"sum_group_14\": \"Sustainable Agricultural Lands Conservation Program\",\n",
    "    \"sum_group_41\": \"Affordable Housing and Sustainable Communities Program\",\n",
    "    \"sum_group_45\": \"Urban and Community Forestry\",\n",
    "    \"sum_group_68\": \"Low Carbon Transit Operations Program\",\n",
    "    \"sum_group_72\": \"State Water Project Turbines\",\n",
    "    \"sum_group_76\": \"Wetlands and Watershed Restoration\",\n",
    "    \"sum_group_78\": \"Transit and Intercity Rail Capital Program\",\n",
    "    \"sum_group_80\": \"Single-Family Solar Photovoltaics (PV)\",\n",
    "    \"sum_group_82\": \"Water-Energy Grant Program\",\n",
    "    \"sum_group_86\": \"Forest Health Program\",\n",
    "    \"sum_group_88\": \"Single-Family Energy Efficiency and Solar PV\",\n",
    "    \"sum_group_90\": \"Multi-Family Energy Efficiency and Renewables\",\n",
    "    \"sum_group_120\": \"Agricultural Worker Vanpools\",\n",
    "    \"sum_group_124\": \"Rural School Bus Pilot Projects\",\n",
    "    \"sum_group_128\": \"Woodsmoke Reduction Program\",\n",
    "    \"sum_group_130\": \"Active Transportation Program\",\n",
    "    \"sum_group_132\": \"Organics and Recycling Loans\",\n",
    "    \"sum_group_134\": \"Recycled Fiber, Plastic, and Glass Grant Program\",\n",
    "    \"sum_group_136\": \"Food Waste Prevention and Rescue Grants\",\n",
    "    \"sum_group_138\": \"Urban Greening Program\",\n",
    "    \"sum_group_142\": \"Transformative Climate Communities (Community)\",\n",
    "    \"sum_group_148\": \"Organics Grants\",\n",
    "    \"sum_group_189\": \"Community Solar Pilot\",\n",
    "    \"sum_group_191\": \"Alternative Manure Management Program\",\n",
    "    \"sum_group_193\": \"Healthy Soils Program\",\n",
    "    \"sum_group_235\": \"Community Air Protection Incentives\",\n",
    "    \"sum_group_237\": \"Funding Agricultural Replacement Measures for Emission Reductions Program\",\n",
    "    \"sum_group_239\": \"Coastal Resilience Planning\",\n",
    "    \"sum_group_243\": \"Climate Change Adaptation and Coastal Resilience Planning\",\n",
    "    \"sum_group_245\": \"Fire Prevention Program\",\n",
    "    \"sum_group_247\": \"Wildfire Prevention Grants Program\",\n",
    "    \"sum_group_249\": \"Wildfire Response and Readiness\",\n",
    "    \"sum_group_251\": \"Climate Adaptation and Resiliency Program\",\n",
    "    \"sum_group_253\": \"Climate Ready Program\",\n",
    "    \"sum_group_255\": \"Climate Change Research Program\",\n",
    "    \"sum_group_257\": \"Food Production Investment Program\",\n",
    "    \"sum_group_259\": \"Renewable Energy for Agriculture Program\",\n",
    "    \"sum_group_261\": \"Training and Workforce Development Program\",\n",
    "    \"sum_group_263\": \"Clean Off Road Equipment Voucher Incentive Project\",\n",
    "    \"sum_group_265\": \"Community Air Grants\",\n",
    "    \"sum_group_267\": \"Zero-and Near Zero-Emission Freight Facilities Project\",\n",
    "    \"sum_group_269\": \"Advanced Technology Demonstration and Pilot Projects\",\n",
    "    \"sum_group_271\": \"Advanced Technology Demonstration and Pilot Projects\",\n",
    "    \"sum_group_329\": \"Transformative Climate Communities (Household)\",\n",
    "    \"sum_group_331\": \"Prescribed Fire and Smoke Monitoring Program\",\n",
    "    \"sum_group_333\": \"Forest Carbon Plan Implementation\",\n",
    "    \"sum_group_335\": \"Low-Carbon Fuel Production Program\",\n",
    "    \"sum_group_337\": \"Farmworker Housing\",\n",
    "    \"sum_group_339\": \"Regional Forest and Fire Capacity\",\n",
    "    \"sum_group_341\": \"Community Assistance for Climate Equity Program\",\n",
    "    \"sum_group_345\": \"Clean Mobility in Schools Project\",\n",
    "    \"sum_group_471\": \"Outreach, Education, and Awareness\",\n",
    "    \"sum_group_475\": \"Fluorinated Gases Emission Reduction Incentives\",\n",
    "    \"sum_group_477\": \"Transition to a Carbon-Neutral Economy\",\n",
    "    \"sum_group_479\": \"Forest Health Research\",\n",
    "    \"sum_group_547\": \"Advanced Technology Demonstration and Pilot Projects\",\n",
    "    \"sum_group_549\": \"Safe and Affordable Drinking Water Fund\",\n",
    "    \"sum_group_613\": \"Low-Carbon Economy Workforce\",\n",
    "    \"sum_group_615\": \"Fire Engines and Maintenance\",\n",
    "    \"sum_group_617\": \"AB617 Implementation Funds\",\n",
    "    \"sum_group_619\": \"Community Composting for Green Spaces Grant Program\",\n",
    "    \"sum_group_621\": \"Community Fire Planning and Preparedness\",\n",
    "    \"sum_group_690\": \"Reuse Grant Program\",\n",
    "    \"sum_group_695\": \"Sustainable Transportation Equity Project\",\n",
    "    \"sum_group_765\": \"Climate Smart Agriculture Technical Assistance Program\",\n",
    "    \"sum_group_837\": \"IDEAL ZEV Workforce Pilot Project\",\n",
    "    \"sum_group_839\": \"SB 1383 Local Assistance Grant Program\",\n",
    "    \"sum_group_981\": \"Co-Digestion Grant Program\"\n",
    "}\n",
    "\n",
    "# Update the Program_Column field\n",
    "with arcpy.da.UpdateCursor(Funding_Dist_long, [\"Program_Column\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] in column_mapping:\n",
    "            row[0] = column_mapping[row[0]]  # Replace with the new name\n",
    "            cursor.updateRow(row)\n",
    "\n",
    "print(\"Program_Column values renamed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save both formats as layer packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature layer 'FeatureLayer_Long' created successfully.\n",
      "Layer package saved successfully at: C:\\Users\\gcowan\\Documents\\ArcGIS\\Projects\\Distribution Analysis\\Data Restructure\\Data_Restructure\\Funding_Dist_long.lpkx\n",
      "Temporary layer 'FeatureLayer_Long' deleted.\n",
      "Feature layer 'FeatureLayer_Wide' created successfully.\n",
      "Layer package saved successfully at: C:\\Users\\gcowan\\Documents\\ArcGIS\\Projects\\Distribution Analysis\\Data Restructure\\Data_Restructure\\Funding_Dist_wide.lpkx\n",
      "Temporary layer 'FeatureLayer_Wide' deleted.\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "Funding_Dist_long = f\"{project_gdb}\\\\Funding_Dist_{suffix}_long\"\n",
    "Funding_Dist_wide = f\"{project_gdb}\\\\Funding_Dist_{suffix}_wide\"\n",
    "\n",
    "layer_long_name = \"FeatureLayer_Long\"\n",
    "layer_wide_name = \"FeatureLayer_Wide\"\n",
    "\n",
    "FundingDist_lpkx_long = r\"C:\\Users\\gcowan\\Documents\\ArcGIS\\Projects\\Distribution Analysis\\Data Restructure\\Data_Restructure\\Funding_Dist_long.lpkx\"\n",
    "FundingDist_lpkx_wide = r\"C:\\Users\\gcowan\\Documents\\ArcGIS\\Projects\\Distribution Analysis\\Data Restructure\\Data_Restructure\\Funding_Dist_wide.lpkx\"\n",
    "\n",
    "# Save 'long' version layer package\n",
    "try:\n",
    "    # Step 1: Create a feature layer\n",
    "    arcpy.management.MakeFeatureLayer(Funding_Dist_long, layer_long_name)\n",
    "    print(f\"Feature layer '{layer_long_name}' created successfully.\")\n",
    "\n",
    "    # Step 2: Create a layer package\n",
    "    arcpy.management.PackageLayer(layer_long_name, FundingDist_lpkx_long, \"PRESERVE\", \"CONVERT_ARCSDE\", \"DEFAULT\", \"ALL\")\n",
    "    print(f\"Layer package saved successfully at: {FundingDist_lpkx_long}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Cleanup: Delete the temporary layer\n",
    "    if arcpy.Exists(layer_long_name):\n",
    "        arcpy.management.Delete(layer_long_name)\n",
    "        print(f\"Temporary layer '{layer_long_name}' deleted.\")\n",
    "\n",
    "# Save 'wide' version layer package\n",
    "try:\n",
    "    # Step 1: Create a feature layer\n",
    "    arcpy.management.MakeFeatureLayer(Funding_Dist_wide, layer_wide_name)\n",
    "    print(f\"Feature layer '{layer_wide_name}' created successfully.\")\n",
    "\n",
    "    # Step 2: Create a layer package\n",
    "    arcpy.management.PackageLayer(layer_wide_name, FundingDist_lpkx_wide, \"PRESERVE\", \"CONVERT_ARCSDE\", \"DEFAULT\", \"ALL\")\n",
    "    print(f\"Layer package saved successfully at: {FundingDist_lpkx_wide}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Cleanup: Delete the temporary layer\n",
    "    if arcpy.Exists(layer_wide_name):\n",
    "        arcpy.management.Delete(layer_wide_name)\n",
    "        print(f\"Temporary layer '{layer_wide_name}' deleted.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
